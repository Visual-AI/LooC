###
# 修改记录：
# sim_loss 2
# sim_loss 将计算loss的权重，和是否计算该loss分开；便于计算loss但将权重为0，仅用于记录二不参与训练
# 其他实验：
# 添加参数delay: 0: CVQ的计算, 其他>0的数字，0.1， 则采用固定delay
# 
###


Enable_Wandb: False   # for debug

##### train
# exp_name: fashion-mnist_512x64-exp1022_04  # 观察不使用sim_loss参与训练时，sim_loss的变化曲线，用于对比分析

exp_name: ffhq_256x64

output_folder: ./debug

dataset: ffhq

batch_size: 128
num_epochs: 500       # number of epochs (default: 100)
seed: 42              # seed for everything
lr: 3e-4
num_workers: 16

# loss
calc_sim_loss: Ture
sim_loss: 0             # 权重为0，则表示不参与训练；仅 calc_sim_loss=True & sim_loss > 0时参与训练

commitment_cost: 0.25   # hyperparameter for the commitment loss (default: 0.25)


# model
# Latent space
hidden_size: 128        # size of the latent vectors (default: 128)
num_residual_hidden: 32 # size of the redisual layers (default: 32)
num_residual_layers: 2  # number of residual layers (default: 2)

# codebook
# Quantiser parameters
shuffle_scale: 2        # scale factor for upsample and downsample the feature vectors
num_embedding: 256      # number of codebook (default: 512)
dim_embedding: 64
# size_dmbedding: num_embedding * dim_embedding

distance: cos           # distance for codevectors and features
split_type: fixed       # fixed, interval, random
anchor: closest         # anchor sampling methods (random, closest, probrandom)


##### test
# model_name: {exp_name}/'best.pt'
# batch_size: 16


##### eval
num_test: 0  # how many examples to load for testing (default: 0 to test all samples)
# ori_path: ${output_folder}/results/{exp_name}/best.pt/original
# rec_path: ${output_folder}/results/{exp_name}/best.pt/rec


# server vislab 12
# data_folder: /data2/common/fashion-mnist
# data_folder: /data2/common/ImageNet
# data_folder: /data2/common/ffhq/images1024x1024
data_folder: /data2/common/ffhq/thumbnails128x128

# server vislab 13
# data_folder: /home2/jieli/datasets/fashion-mnist


# ----
# CUDA_VISIBLE_DEVICES=1 python main.py --cfg ./config/ffhq_256x64.yaml 2>&1 | tee ./.logs/ffhq_256x64_train.log

 